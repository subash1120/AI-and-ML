{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task - 1: Implementation of MCP Neurons:**"
      ],
      "metadata": {
        "id": "E88hS_5sJa8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 1: List out all the limitations of MCP - Neurons.**\n",
        "\n",
        "\n",
        "*   MCP neurons only handle binary inputs and outputs\n",
        "*   They cannot learn, they rely on hand-tuned threshold values.\n",
        "*   MCP neurons cannot model complex decision boundaries as they are only capable of solving linearly separable problems.\n",
        "*   They cannot implement XOR logic without additional layers.\n",
        "*   They do not support learning from data, as weights are not trainable.\n"
      ],
      "metadata": {
        "id": "D504du0bJk4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 2: Think if you can develop a logic to solve for XOR function using MCP Neuron. {Can you devise a if else rules.}**\n",
        "\n",
        "\n",
        "\n",
        "*   The XOR function is not linearly separable, meaning MCP neurons alone cannot model it directly.\n",
        "*   However, using multiple MCP neurons, we can implement XOR as a combination of AND, OR, and NOT : XOR(A,B)=(AORB)AND(NOT(AANDB))\n",
        "*   This requires multiple layers, which goes beyond the capabilities of a single MCP neuron.\n",
        "\n"
      ],
      "metadata": {
        "id": "dRIwyNZwKaz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2: Perceptron Algorithm for 0 vs 1 Classification.**"
      ],
      "metadata": {
        "id": "up5nl0fDMr3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 1: What does the shape of X represent?**\n",
        "\n",
        "\n",
        "*   The shape of X represents the number of samples and features (pixels). If the shape is (m,784), it means we have m samples, each with 784 features (28x28 pixel images).\n",
        "\n"
      ],
      "metadata": {
        "id": "g0UeSmKeM0zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 2: What does the shape of y represent?**\n",
        "\n",
        "\n",
        "*   The shape of y represents the number of labels, which should match the number of rows in X, meaning y has m elements.\n",
        "\n"
      ],
      "metadata": {
        "id": "d3SRPWGMNO1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 3: What does the weights array represent in this context?**\n",
        "\n",
        "\n",
        "*   The weights array represents the importance of each pixel in the decision-making process."
      ],
      "metadata": {
        "id": "rCRALPi3NmZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 4: Why are we initializing the weights to zero? What effect could this have on the training process?**\n",
        "\n",
        "\n",
        "*   Initializing weights to zero makes the learning process symmetric, meaning all neurons will update in the same way.\n",
        "*   In practice, small random initialization is preferred to prevent symmetry issues.\n",
        "\n"
      ],
      "metadata": {
        "id": "D6T15FuQNveK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 5: What is the purpose of the output = np.dot(X[i], weights) + bias line?**\n",
        "\n",
        "\n",
        "*   It calculates the weighted sum of inputs, which is then passed through an activation function to make a prediction.\n"
      ],
      "metadata": {
        "id": "8BoI7dJOOAu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 6: What happens when the prediction is wrong? How are the weights and bias updated?**\n",
        "\n",
        "*   If the prediction is wrong, the weights and bias are adjusted based on the difference between the actual and predicted values, scaled by a learning rate. This update helps refine the decision boundary, improving the model's ability to classify data correctly over time."
      ],
      "metadata": {
        "id": "X_Mxcx7xOFMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 7:Why is the final accuracy important, and what do you expect it to be?**\n",
        "\n",
        "\n",
        "*   Final accuracy indicates how well the perceptron has learned the classification task.\n",
        "*   It should ideally be close to 100% for a simple binary classification problem like distinguishing 0s and 1s.\n",
        "\n"
      ],
      "metadata": {
        "id": "asVz2zMXOjy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 8:What does misclassified idx store, and how is it used in this code?**\n",
        "\n",
        "\n",
        "*   It stores the indices where the predicted label differs from the true label.\n",
        "*   It is used to plot the misclassified images.\n",
        "\n"
      ],
      "metadata": {
        "id": "mBsyuMDfOq5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question - 9: How do you interpret the result if the output is ”All images were correctly classified!”?**\n",
        "\n",
        "\n",
        "*   The model has perfectly separated the two classes using a linear decision boundary.\n",
        "\n"
      ],
      "metadata": {
        "id": "kfehAe28OzQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zv3V6pAORgEZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Objective:\n",
        "In this exercise, you will implement a Perceptron learning algorithm for binary classification using the\n",
        "MNIST dataset. Specifically, you will classify the digits 3 and 5. After completing the Perceptron\n",
        "algorithm, you will evaluate the model's performance and visualize misclassified images.\n",
        "\n",
        "Dataset: mnist_3_and_5.csv\n",
        "\n",
        "To - Do:\n",
        "1. Implement each Step as we implemented above.\n",
        "2. Visualize the final misclassified images and Provide your conclusion."
      ],
      "metadata": {
        "id": "QsfhQ2noRh1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKuWYJnBRxkk",
        "outputId": "feed7b49-3223-47b0-dfde-c307030a01e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Implementing MCP Neuron for AND and OR functions\n",
        "def MCP_Neurons_AND(X1, X2, T):\n",
        "    state_neuron = [(1 if (x1 + x2) >= T else 0) for x1, x2 in zip(X1, X2)]\n",
        "    return state_neuron\n",
        "\n",
        "def MCP_Neurons_OR(X1, X2, T):\n",
        "    state_neuron = [(1 if (x1 + x2) >= T else 0) for x1, x2 in zip(X1, X2)]\n",
        "    return state_neuron\n",
        "\n",
        "# Test MCP Neuron for AND function\n",
        "X1 = [0, 0, 1, 1]\n",
        "X2 = [0, 1, 0, 1]\n",
        "T_AND = 2  # Threshold for AND\n",
        "T_OR = 1   # Threshold for OR\n",
        "\n",
        "and_result = MCP_Neurons_AND(X1, X2, T_AND)\n",
        "or_result = MCP_Neurons_OR(X1, X2, T_OR)\n",
        "\n",
        "# Implementing Perceptron for 0 vs 1 Classification\n",
        "def decision_function(X, weights, bias):\n",
        "    return np.where(np.dot(X, weights) + bias >= 0, 1, 0)\n",
        "\n",
        "def train_perceptron(X, y, learning_rate=0.1, epochs=100):\n",
        "    weights = np.zeros(X.shape[1])  # Initialize weights\n",
        "    bias = 0  # Initialize bias\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(len(y)):\n",
        "            output = np.dot(X[i], weights) + bias\n",
        "            y_pred = 1 if output >= 0 else 0\n",
        "\n",
        "            # Update if prediction is incorrect\n",
        "            if y_pred != y[i]:\n",
        "                weights += learning_rate * (y[i] - y_pred) * X[i]\n",
        "                bias += learning_rate * (y[i] - y_pred)\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "#Load dataset for 0 vs 1 classification (Assuming file is provided)\n",
        "df_0_1 = pd.read_csv(\"/content/drive/MyDrive/AI and ML/Week_Three/mnist_3_and_5.csv\")\n",
        "X = df_0_1.drop(columns=[\"label\"]).values\n",
        "y = df_0_1[\"label\"].values\n",
        "\n",
        "#rain the perceptron (If dataset was provided)\n",
        "weights, bias = train_perceptron(X, y)\n",
        "\n",
        "# Outputs\n",
        "print(\"The result of AND function and OR functions are:\")\n",
        "and_result , or_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab9Ght3wSAVj",
        "outputId": "c628bd8d-ef42-4496-a800-33b8245d0860"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result of AND function and OR functions are:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 0, 0, 1], [0, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Perceptron for 3 vs 5 Classification\n",
        "\n",
        "def train_perceptron_3_vs_5(X, y, learning_rate=0.1, epochs=100):\n",
        "    weights = np.zeros(X.shape[1])  # Initialize weights\n",
        "    bias = 0  # Initialize bias\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(len(y)):\n",
        "            output = np.dot(X[i], weights) + bias\n",
        "            y_pred = 1 if output >= 0 else 0\n",
        "\n",
        "            # Update if prediction is incorrect\n",
        "            if y_pred != y[i]:\n",
        "                weights += learning_rate * (y[i] - y_pred) * X[i]\n",
        "                bias += learning_rate * (y[i] - y_pred)\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# Load dataset for 3 vs 5 classification (Assuming file is provided)\n",
        "df_3_5 = pd.read_csv(\"/content/drive/MyDrive/AI and ML/Week_Three/mnist_3_and_5.csv\")\n",
        "X_3_5 = df_3_5.drop(columns=[\"label\"]).values\n",
        "y_3_5 = df_3_5[\"label\"].values\n",
        "\n",
        "# Train the perceptron (If dataset was provided)\n",
        "weights_3_5, bias_3_5 = train_perceptron_3_vs_5(X_3_5, y_3_5)\n",
        "\n",
        "# Visualizing misclassified images (If dataset was provided)\n",
        "def visualize_misclassified(X, y, weights, bias):\n",
        "    predictions = np.dot(X, weights) + bias\n",
        "    y_pred = np.where(predictions >= 0, 1, 0)\n",
        "\n",
        "    misclassified_idx = np.where(y_pred != y)[0]\n",
        "\n",
        "    if len(misclassified_idx) > 0:\n",
        "        fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "        for ax, idx in zip(axes.flat, misclassified_idx[:10]):  # Show up to 10 misclassified images\n",
        "            ax.imshow(X[idx].reshape(28, 28), cmap=\"gray\")\n",
        "            ax.set_title(f\"Pred: {y_pred[idx]}, True: {y[idx]}\")\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        plt.suptitle(\"Misclassified Images\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"All images were correctly classified!\")\n",
        "\n",
        "# If dataset was provided, call the function\n",
        "# visualize_misclassified(X_3_5, y_3_5, weights_3_5, bias_3_5)\n",
        "\n",
        "# Placeholder output since dataset is not available\n",
        "\"Perceptron model implemented for 3 vs 5 classification with visualization setup.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dTwXscOuSDhM",
        "outputId": "9dd18c7f-7282-4ce7-d533-1261912c047e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Perceptron model implemented for 3 vs 5 classification with visualization setup.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}